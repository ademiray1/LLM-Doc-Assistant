
# ğŸ“„ LLM Doc Assistant

A lightweight, full-stack RAG (Retrieval-Augmented Generation) app that allows users to upload **PDFs, Word documents, PowerPoints, or TXT files**, then ask **natural language questions** or generate **summaries** â€” powered entirely by **local LLMs via Ollama**.

## ğŸŒ Live Preview

> Upload a document â†’ Ask a question â†’ Get an intelligent response  
> Powered by: `Flask` + `FastAPI` + `LangChain` + `Ollama` + `FAISS`

---

## ğŸš€ Features

âœ… Upload `.pdf`, `.docx`, `.pptx`, `.txt` files  
âœ… Ask contextual questions about your documents  
âœ… Summarization and Q&A handled locally with Ollama  
âœ… Modular FastAPI backend with LangChain pipeline  
âœ… Lightweight Flask UI for easy interaction  
âœ… Vectorized document storage using FAISS

---

## âš™ï¸ Tech Stack

| Layer        | Tool                | Purpose                        |
|--------------|---------------------|--------------------------------|
| UI           | Flask + HTML/CSS    | File upload + prompt input     |
| API          | FastAPI             | Handles prompt & doc logic     |
| LLM          | Ollama (e.g. Mistral)| Local language model inference |
| Embeddings   | Ollama + LangChain  | Vectorizing document chunks    |
| RAG Pipeline | LangChain           | Retrieval-augmented generation |
| Vector Store | FAISS               | In-memory search for retrieval |

---

## ğŸ’¡ Why Local RAG Matters

Using a local RAG setup like this:

- âœ… Keeps your sensitive documents **private**
- âœ… No cloud API cost, no rate limits
- âœ… Works offline once models are pulled
- âœ… Fully hackable and extendable
- âœ… Built for personal knowledge bases, enterprise docs, or internal tools

---

## ğŸ›  Setup

1. **Clone the repo**
2. Create virtual environment & activate:
   ```bash
   python -m venv venv && source venv/bin/activate
   ```
3. Install dependencies:
   ```bash
   pip install -r requirements.txt
   ```
4. Pull required Ollama models:
   ```bash
   ollama pull mistral
   ollama pull nomic-embed-text
   ```
5. Start services:
   - In one terminal:
     ```bash
     python -m uvicorn fastapi_backend.main:app --reload
     ```
   - In another terminal:
     ```bash
     python flask_ui/app.py
     ```
6. Visit `http://localhost:5000` and enjoy!

---

## ğŸ“¸ Screenshot

> Example: Upload a PDF agenda â†’ Ask "What is this document about?"  
> ![screenshot](./screenshot.png)

---

## ğŸ§  TODOs / Next Features

- [ ] âœ… Add **multi-file upload** and multi-document context
- [ ] âœ… Implement **chat-style continuous conversation** (ConversationalRetrievalChain)
- [ ] âœ… Add user-level **API key access and auth**
- [ ] ğŸŒŸ Add **offline PDF agent**: extract structured metadata (dates, amounts, names)
- [ ] ğŸŒŸ Add **voice-to-question**: Ask questions via microphone input
- [ ] ğŸ’¡ Add **"doc memory mode"**: Let users upload a file and revisit chat later

---

## ğŸ’¬ Cool Use Cases

- ğŸ“š **Reading long research papers or contracts** â€” Skip to what matters with fast, intelligent summaries and contextual Q&A.
- ğŸ¢ **Internal company docs, handbooks, or HR policies** â€” Ask natural questions instead of digging through pages.
- ğŸ›  **Factory maintenance manuals or SOPs** â€” Instantly get step-by-step procedures for tools or machines by asking "How do I reset machine X?" or "What's the PM checklist for tool Y?"
- ğŸ§  **Personal knowledge base** â€” Upload all your favorite PDFs, notes, or guides and interact with them like ChatGPT.
- ğŸ§¾ **Legal, compliance, and audit docs** â€” Summarize or extract obligations, dates, clauses from long legal paperwork.
- ğŸ§ª **Scientific papers** â€” Ask "What is the main hypothesis?" or "What methods were used?" and get contextual answers.

---

## ğŸ™Œ Credits

- [LangChain](https://www.langchain.com/)
- [Ollama](https://ollama.com/)
- [FAISS](https://github.com/facebookresearch/faiss)
